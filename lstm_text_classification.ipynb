{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying News Articles Using LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be using TorchText, which is PyTorch text library providing advanced functionalities on language processing.\n",
    "\n",
    "The dataset we'll be using is AG News. AG News (AG’s News Corpus) is a subdataset of AG's corpus of news articles constructed by assembling titles and description fields of articles from the 4 largest classes (“World”, “Sports”, “Business”, “Sci/Tech”) of AG’s Corpus. The AG News contains 30,000 training and 1,900 test samples per class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.datasets import AG_NEWS\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.transforms as T\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from NewsDataset import NewsDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the AG News Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Create custom NewsDataset from dataframe\n",
    "dataset_train = NewsDataset(df_train)\n",
    "dataset_test = NewsDataset(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4  # Learning rate for the optimizer\n",
    "nepochs = 20  # Number of training epochs\n",
    "batch_size = 32  # Batch size for training\n",
    "max_len = 128  # Maximum length of input sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "Tokenization is the process of splitting a text into individual words or tokens.\n",
    "\n",
    "Here, we use the `get_tokenizer` function from the `torchtext.data.utils` module to create a tokenizer based on the \"basic_english\" tokenization method.\n",
    "\n",
    "Then we define a generator function `yield_tokens` to yield tokens from the data iterator, processing both the title and the description. From these tokens we can build the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer(\"basic_english\")\n",
    "\n",
    "def yield_tokens(df):\n",
    "    for _, row in df.iterrows():\n",
    "        yield tokenizer(row['Title'])\n",
    "        yield tokenizer(row['Description'])\n",
    "\n",
    "\n",
    "# Build the vocabulary from the tokens yielded by the `yield_tokens` generator function.\n",
    "# We set `min_freq=2` to include a token only if it appears more than 2 times in the dataset.\n",
    "\n",
    "# We will also add \"special\" tokens that we'll use to signal something to our model\n",
    "# <pad> is a padding token that is added to the end of a sentence to ensure \n",
    "# the length of all sequences in a batch is the same\n",
    "# <sos> signals the \"Start-Of-Sentence\" aka the start of the sequence\n",
    "# <eos> signal the \"End-Of-Sentence\" aka the end of the sequence\n",
    "# <unk> \"unknown\" token is used if a token is not contained in the vocab\n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(df_train),  # Tokenized data iterator\n",
    "    min_freq=2,  # Minimum frequency threshold for token inclusion\n",
    "    specials=['<pad>', '<sos>', '<eos>', '<unk>'],  # Special case tokens\n",
    "    special_first=True  # Place special tokens first in the vocabulary\n",
    ")\n",
    "\n",
    "# Set the default index of the vocabulary to the index of the '<unk>' token.\n",
    "# If a token is not found in the vocabulary, it will be replaced with the '<unk>' token.\n",
    "vocab.set_default_index(vocab['<unk>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets have a look at the vocab!\n",
    "vocab.get_itos()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a text transformation pipeline using TorchText Sequential Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tranform = T.Sequential(\n",
    "    # Convert the sentences to indices based on the given vocabulary\n",
    "    T.VocabTransform(vocab=vocab),\n",
    "    # Add <sos> at the beginning of each sentence. 1 is used because the index for <sos> in the vocabulary is 1.\n",
    "    T.AddToken(1, begin=True),\n",
    "    # Crop the sentence if it is longer than the max length\n",
    "    T.Truncate(max_seq_len=max_len),\n",
    "    # Add <eos> at the end of each sentence. 2 is used because the index for <eos> in the vocabulary is 2.\n",
    "    T.AddToken(2, begin=False),\n",
    "    # Convert the list of lists to a tensor. This also pads a sentence with the <pad> token if it is shorter than the max length,\n",
    "    # ensuring that all sentences are the same length.\n",
    "    T.ToTensor(padding_value=0)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a lambda function for tokenizing each batch of text data\n",
    "text_tokenizer = lambda batch: [tokenizer(x) for x in batch]\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "data_loader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True, num_workers=4, drop_last=True)\n",
    "data_loader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Genome of the mammalian common ancestor reconstructed Using computer programs,scientists have suceeded in reconstructing the DNA of a creature that lived at the time of the dinosaurs more than 75 million years ago, a small, furry nocturnal animal that was the common ancestor of all placental mammals ',\n",
       " \"Advertising Spending to Grow '05 - Buyers   LONDON/NEW YORK (Reuters) - Advertising spending will grow  robustly in 2005 despite the absence of events like the  Olympics, media buying agencies Universal McCann and Zenith  Optimedia said on Monday as they raised their forecasts.\",\n",
       " 'Nasa launches cosmic blast hunter Nasa launches the Swift observatory to study gamma-ray bursts - the biggest explosions since the Big Bang.',\n",
       " 'Microsoft hears jingle of cash register software With a specialized version of Windows XP Embedded, the software maker wants to get its fingers in the till.\\\\',\n",
       " 'Hypertension Hurts Brain Function in Young By Kathleen Doheny, HealthDay Reporter    Study finds hypertension erodes cognitive ability in those of all ages    HealthDayNews -- For years, experts have known that high blood pressure is related to poor cognitive performance in older adults and can lead to adverse changes in the brain.    Now, researchers report that young adults with high blood pressure are just as susceptible to decreased mental function as are older people are...',\n",
       " 'Moroccan Charged in Europe Terror Probe (AP) AP - A judge charged a jailed Moroccan on Tuesday with being a leading member of Islamic extremist groups in three countries, including an organization suspected in the killing of a Dutch filmmaker.',\n",
       " 'Savor Beltran while he #39;s hot HOUSTON -- The attitude of every team in the postseason is: concentrate on today and let tomorrow take care of itself. That would be a good strategy for baseball-watchers, too, especially when they watch Carlos Beltran.',\n",
       " 'BBC trimming 6,000 jobs by year-end The BBC has announced it is cutting 6,000 jobs, primarily from the British broadcaster #39;s news and production staffs, by year-end.',\n",
       " 'IMF Chief Sees Potential Hazard in US Fiscal Policies he managing director of the International Monetary Fund, Rodrigo de Rato, said yesterday that the dollar would have to fall and the United States would have to tackle its growing indebtedness ',\n",
       " 'Financial network to end after nine years CNN will shut down its struggling CNNfn financial news network in mid-December, giving up its attempt after nine years to compete in a market dominated by CNBC.',\n",
       " 'Israeli Airborne Attack Kills Inventor of Qassam Rocket Adnan Al-Gul, the inventor of the Qassam rockets used by Palestinians to attack Israel, was killed yesterday in an air attack on Gaza.',\n",
       " 'No. 3 Georgia Tech Routs Alabama St. 74-37 (AP) AP - Jarrett Jack scored 20 points and No. 3 Georgia Tech held Alabama State scoreless for more than nine minutes at the start in a 74-37 rout on Friday.',\n",
       " \"Pols, Don't Count on Recounts The 100,000 electronic voting machines in use in Tuesday's election have a big downside: Candidates who dispute the results won't have a way to conduct a meaningful recount. Analysis by Kim Zetter.\",\n",
       " 'New GNOME Released The GNOME Foundation today released the latest evolution of its widely used Linux desktop GNOME version 2.8. The new release adds some significant new features and further expands the usability of the Linux desktop.',\n",
       " 'Oil prices raise cost of gasoline LOS ANGELES - Gasoline prices have climbed nearly 8 cents a gallon in the last two weeks because of record-high crude oil prices, and they are likely to continue rising, an industry analyst said Sunday.',\n",
       " \"Tennis: Ferrero falls in epic Last year's runner-up Juan Carlos Ferrero goes out of the US Open after a five-set battle with Stefan Koubek.\",\n",
       " 'Israeli forces detain senior Hamas militant Israeli forces detained a senior leader of Hamas #39;s military wing in the West Bank today during a night-time raid on his hideout, witnesses said.',\n",
       " 'Intel Proposes Internet Transformation  quot;These new smart services could allow the Internet to detect and warn of worm attacks on its own, dynamically re-route network traffic to avoid delays, and improve video web casting, quot; said Intel ',\n",
       " \"Photos: 'Wanna buy an iPod, guv?' Apple's new London store on Regent Street puts the iPod music player front and center.\",\n",
       " 'Mandrake goes Official with Linux MORENO VALLEY, Calif., and PARIS, Oct. 28 - Mandrakesoft has released Mandrakelinux 10.1 Official, the latest version of its Linux operating system.',\n",
       " 'Agent: Nothing to Alonzo #39;s return His agent says there #39;s nothing to reports that Alonzo Mourning plans another comeback, the New Jersey Nets say they wouldn #39;t be surprised if he tried and the man himself isn #39;t saying anything.',\n",
       " \"Mid-East peace claims 'premature' Israel dismisses reports from Egypt that a peace plan has been agreed with the Palestinians as premature.\",\n",
       " 'Boingo, Vonage Join on Wireless VoIP Boingo Wireless and Vonage are teaming to provide voice over Wi-Fi service as a complement to traditional VoIP. Initially, the companies will collaborate on a service bundle that combines Vonage #39;s ',\n",
       " 'Halo 2 gets down to Earth You #39;ve read the ads, heard the buzz and seen the long lineups on the news, but does Halo 2 live up to the hype? Yes. Played from an immersive first-person perspective, the original Halo: Combat Evolved was ',\n",
       " 'Iraqi president throws support behind Jan. 30 election BAGHDAD -- President Ghazi al-Yawer of Iraq, an influential Sunni Muslim, threw his support yesterday behind holding the Jan. 30 election on time despite insurgent threats he said have paralyzed voter registration in some Sunni areas.',\n",
       " 'Barber #39;s reinvention helps lift Giants (Oct. 6, 2004) -- The New York Giants easily qualify as one of the biggest surprise teams of the first quarter of the NFL season. And Tiki Barber easily qualifies as one of their biggest surprise players.',\n",
       " 'Cisco Source Code Offered for Sale an anonymous group of hackers -- has surfaced on the Internet once again. This time, the SCC is selling source code for a Cisco security application in another blatant violation of copyright regulations.',\n",
       " 'Singapore Budget Carrier Set to Take Off Singapore Airlines #39; low-cost arm raised the stakes Monday in the battle for budget travelers, saying it is ready for a price war as it prepares to begin services next month.',\n",
       " 'Symantec releases patching tool Security company Symantec Corp. plans to announce the release of a patch management product on Monday that it says will enable small and medium-sized businesses (SMBs) to stay on top of software vulnerabilities.',\n",
       " \"Oracle buys PeopleSoft for \\\\$10 billion Ening a bitter battle, PeopleSoft's board has finally approved a deal worth around \\\\$10 billion Oracle says.\",\n",
       " 'XP price cut may be just the beginning (SiliconValley.com) SiliconValley.com - A tiny yet important crack has opened, with little notice, in the great Windows monopoly that surrounds personal computing.',\n",
       " 'Managing Credit Cards Intelligently Take advantage of cards instead of it being the other way around.')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label, text = next(iter(data_loader_train))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_emb, output_size, num_layers=1, hidden_size=128):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        # Create an embedding layer to convert token indices to dense vectors\n",
    "        self.embedding = nn.Embedding(num_emb, hidden_size)\n",
    "        \n",
    "        # Define the LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, \n",
    "                            num_layers=num_layers, batch_first=True, dropout=0.5)\n",
    "        \n",
    "        # Define the output fully connected layer\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq, hidden_in, mem_in):\n",
    "        # Convert token indices to dense vectors\n",
    "        input_embs = self.embedding(input_seq)\n",
    "\n",
    "        # Pass the embeddings through the LSTM layer\n",
    "        output, (hidden_out, mem_out) = self.lstm(input_embs, (hidden_in, mem_in))\n",
    "                \n",
    "        # Pass the LSTM output through the fully connected layer to get the final output\n",
    "        return self.fc_out(output), hidden_out, mem_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device to GPU if available, otherwise fallback to CPU\n",
    "device = torch.device(0 if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the size of the hidden layer and number of LSTM layers\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "\n",
    "# Create the LSTM classifier model\n",
    "lstm_classifier = LSTM(num_emb=len(vocab), output_size=4, \n",
    "                       num_layers=num_layers, hidden_size=hidden_size).to(device)\n",
    "\n",
    "# Initialize the optimizer with Adam optimizer\n",
    "optimizer = optim.Adam(lstm_classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# Define the loss function as CrossEntropyLoss for classification\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Initialize lists to store training and test loss, as well as accuracy\n",
    "training_loss_logger = []\n",
    "test_loss_logger = []\n",
    "training_acc_logger = []\n",
    "test_acc_logger = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-This Model Has 3499844 (Approximately 3 Million) Parameters!\n"
     ]
    }
   ],
   "source": [
    "# Let's see how many Parameters our Model has!\n",
    "num_model_params = 0\n",
    "for param in lstm_classifier.parameters():\n",
    "    num_model_params += param.flatten().shape[0]\n",
    "\n",
    "print(\"-This Model Has %d (Approximately %d Million) Parameters!\" % (num_model_params, num_model_params//1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a151f51f4fed46d39d5eebd9e90a112d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d83cf94c8ad404f8aaaadfaad935139",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "343462c270244490a3d87720e39f3b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aa9724256b64273b936c8c61ce7d192",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac0c5fceefd94e07a464d1013f5207c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e385357e9ff4e9da91807248c6542bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "544cfedefe924ef0bde61c948aa533d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae768440b2744308855de78ccfd7c4dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d7474729a8b450f9a16bd7a9f8a48f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72815f4cf1c74b3ab0c4d4a30bb32126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9085817ec3454e90938f298ef745371d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca1157b86f784da7a942669791dcb05d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acbcd0a301e0434dbbc704e8bcefc8e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc903c997d78429aaa26700d2f814063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c7e1053fc84151992840638ea8de0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73168e2bce724060a852fd5eb9cc4028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d2517651d9c41afa30059ebe2829c63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85483fe1ab4a4443befe7f6ecfc7e1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c9acb01f4254a28a92ff2e4c5ae69c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acdede060fc9462281b275e6267e8ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf326966d2b84a90bff3bbd62c3c048c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ea746bc6b740b2aa543534a04ddf17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "373e4b3708ae40d48fa5ec6b94baa4de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "530cf1ff1c8a4051ac4ac9aa2daf547e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56985b61b8f84818ac20fef5cbae5028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd7beef462f4c0eb878b3074905ff05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7e82e5e0be549919bdb4ff6294e79f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c07ef9cb16470e908624fab368b3d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf069095f61488d820a253f51c1ebe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3abb821365e947f18bbae45d5b5b4794",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be6cb179f29445fa89f32b0ac7b904a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0035ba0a2f47caba8f300602b155ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052958bc8cf745dcbf26eb01401b760b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd60d7e89788418e81486c529a00efe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d458f0dea2af4b55b37a95d9cf35840d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bd86a5a9644c09ac366ae37c41b40d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13f09adcd3fe45aea9f7ccb698f4e656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ff597c415b64306aa9f025330e88e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5529e319388450493a1e28317c50809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234596c81bfb4450b8b3d2513c9b97f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training:   0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179a116041294952b3c3fb5f68aad185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing:   0%|          | 0/238 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize tqdm progress bar for epochs\n",
    "pbar = trange(0, nepochs, leave=False, desc=\"Epoch\")\n",
    "\n",
    "# Initialize training and test accuracy\n",
    "train_acc = 0\n",
    "test_acc = 0\n",
    "\n",
    "# Loop through each epoch\n",
    "for epoch in pbar:\n",
    "    # Update progress bar description with current accuracy\n",
    "    pbar.set_postfix_str('Accuracy: Train %.2f%%, Test %.2f%%' % (train_acc * 100, test_acc * 100))\n",
    "    \n",
    "    # Set model to training mode\n",
    "    lstm_classifier.train()\n",
    "    steps = 0\n",
    "    \n",
    "    # Iterate through training data loader\n",
    "    for label, text in tqdm(data_loader_train, desc=\"Training\", leave=False):\n",
    "        bs = label.shape[0]\n",
    "        \n",
    "        # Tokenize and transform text to tensor, move to device\n",
    "        text_tokens = text_tranform(text_tokenizer(text)).to(device)\n",
    "        label = (label - 1).to(device)\n",
    "        \n",
    "        # Initialize hidden and memory states\n",
    "        hidden = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "        memory = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "        \n",
    "        # Forward pass through the model\n",
    "        pred, hidden, memory = lstm_classifier(text_tokens, hidden, memory)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = loss_fn(pred[:, -1, :], label)\n",
    "            \n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Append training loss to logger\n",
    "        training_loss_logger.append(loss.item())\n",
    "        \n",
    "        # Calculate training accuracy\n",
    "        train_acc += (pred[:, -1, :].argmax(1) == label).sum()\n",
    "        steps += bs\n",
    "        \n",
    "    # Calculate and append training accuracy for the epoch\n",
    "    train_acc = (train_acc/steps).item()\n",
    "    training_acc_logger.append(train_acc)\n",
    "    \n",
    "    # Set model to evaluation mode\n",
    "    lstm_classifier.eval()\n",
    "    steps = 0\n",
    "    \n",
    "    # Iterate through test data loader\n",
    "    with torch.no_grad():\n",
    "        for label, text in tqdm(data_loader_test, desc=\"Testing\", leave=False):\n",
    "            bs = label.shape[0]\n",
    "            # Tokenize and transform text to tensor, move to device\n",
    "            text_tokens = text_tranform(text_tokenizer(text)).to(device)\n",
    "            label = (label - 1).to(device)\n",
    "\n",
    "            # Initialize hidden and memory states\n",
    "            hidden = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "            memory = torch.zeros(num_layers, bs, hidden_size, device=device)\n",
    "            \n",
    "            # Forward pass through the model\n",
    "            pred, hidden, memory = lstm_classifier(text_tokens, hidden, memory)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = loss_fn(pred[:, -1, :], label)\n",
    "            test_loss_logger.append(loss.item())\n",
    "\n",
    "            # Calculate test accuracy\n",
    "            test_acc += (pred[:, -1, :].argmax(1) == label).sum()\n",
    "            steps += bs\n",
    "\n",
    "        # Calculate and append test accuracy for the epoch\n",
    "        test_acc = (test_acc/steps).item()\n",
    "        test_acc_logger.append(test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
